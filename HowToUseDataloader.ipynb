{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dataloader\n",
    "from sklearn.datasets import load_digits\n",
    "import importlib\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(loader):\n",
    "    data = loader()\n",
    "    columns = data.get(\"feature_names\")\n",
    "    df = pd.DataFrame(data.data, columns=columns)\n",
    "    df[\"target\"] = pd.Series(data.target)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dataloader' from '/Users/akihirosanada/Documents/Github/sklearn2vantage/dataloader.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"teradata://dbc:dbc@173.168.56.128:1025/tdwork\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_digits= make_df(load_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start dumping DF to /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_tdload_digits_1580542040.csv\n",
      "    ...finished. : elapsed time = 0.15.sec\n",
      "start re-reading /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_tdload_digits_1580542040.csv\n",
      "    ...finished. : elapsed time = 0.02.sec\n",
      "droped table tdwork.tdload_digits\n",
      "created table \n",
      "\n",
      "    create table tdwork.tdload_digits (\n",
      "        col_0 float\n",
      "    ,col_1 float\n",
      "    ,col_2 float\n",
      "    ,col_3 float\n",
      "    ,col_4 float\n",
      "    ,col_5 float\n",
      "    ,col_6 float\n",
      "    ,col_7 float\n",
      "    ,col_8 float\n",
      "    ,col_9 float\n",
      "    ,col_10 float\n",
      "    ,col_11 float\n",
      "    ,col_12 float\n",
      "    ,col_13 float\n",
      "    ,col_14 float\n",
      "    ,col_15 float\n",
      "    ,col_16 float\n",
      "    ,col_17 float\n",
      "    ,col_18 float\n",
      "    ,col_19 float\n",
      "    ,col_20 float\n",
      "    ,col_21 float\n",
      "    ,col_22 float\n",
      "    ,col_23 float\n",
      "    ,col_24 float\n",
      "    ,col_25 float\n",
      "    ,col_26 float\n",
      "    ,col_27 float\n",
      "    ,col_28 float\n",
      "    ,col_29 float\n",
      "    ,col_30 float\n",
      "    ,col_31 float\n",
      "    ,col_32 float\n",
      "    ,col_33 float\n",
      "    ,col_34 float\n",
      "    ,col_35 float\n",
      "    ,col_36 float\n",
      "    ,col_37 float\n",
      "    ,col_38 float\n",
      "    ,col_39 float\n",
      "    ,col_40 float\n",
      "    ,col_41 float\n",
      "    ,col_42 float\n",
      "    ,col_43 float\n",
      "    ,col_44 float\n",
      "    ,col_45 float\n",
      "    ,col_46 float\n",
      "    ,col_47 float\n",
      "    ,col_48 float\n",
      "    ,col_49 float\n",
      "    ,col_50 float\n",
      "    ,col_51 float\n",
      "    ,col_52 float\n",
      "    ,col_53 float\n",
      "    ,col_54 float\n",
      "    ,col_55 float\n",
      "    ,col_56 float\n",
      "    ,col_57 float\n",
      "    ,col_58 float\n",
      "    ,col_59 float\n",
      "    ,col_60 float\n",
      "    ,col_61 float\n",
      "    ,col_62 float\n",
      "    ,col_63 float\n",
      "    ,target integer\n",
      "    ) no primary index\n",
      "    \n",
      "start connecting ssh\n",
      "    ...finished. : elapsed time = 0.20.sec\n",
      "start Uploading File /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_tdload_digits_1580542040.csv to /root/tmp_tdwork_tdload_digits_1580542040.csv\n",
      "Uploading b'tmp_tdwork_tdload_digits_1580542040.csv' progress: 100.00%\n",
      "\n",
      "    ...finished. : elapsed time = 0.22.sec\n",
      "start Loading File /root/tmp_tdwork_tdload_digits_1580542040.csv to DB\n",
      "Teradata Parallel Transporter Version 16.20.00.09 64-Bit\n",
      "\n",
      "The global configuration file '/opt/teradata/client/16.20/tbuild/twbcfg.ini' is used.\n",
      "\n",
      "   Log Directory: /opt/teradata/client/16.20/tbuild/logs\n",
      "\n",
      "   Checkpoint Directory: /opt/teradata/client/16.20/tbuild/checkpoint\n",
      "\n",
      "\n",
      "\n",
      "Job log: /opt/teradata/client/16.20/tbuild/logs/jobtmp-93.out\n",
      "\n",
      "Job id is jobtmp-93, running on linux\n",
      "\n",
      "Teradata Parallel Transporter DataConnector Operator Version 16.20.00.09\n",
      "\n",
      "Teradata Parallel Transporter Load Operator Version 16.20.00.09\n",
      "\n",
      "$LOAD: private log specified: LoadLog\n",
      "\n",
      "$FILE_READER[1]: DataConnector Producer operator Instances: 1\n",
      "\n",
      "$FILE_READER[1]: ECI operator ID: '$FILE_READER-13696'\n",
      "\n",
      "$FILE_READER[1]: Operator instance 1 processing file '/root/tmp_tdwork_tdload_digits_1580542040.csv'.\n",
      "\n",
      "$LOAD: connecting sessions\n",
      "\n",
      "$LOAD: preparing target table\n",
      "\n",
      "$LOAD: entering Acquisition Phase\n",
      "\n",
      "$LOAD: entering Application Phase\n",
      "\n",
      "$LOAD: Statistics for Target Table:  'tdwork.tdload_digits'\n",
      "\n",
      "$LOAD: Total Rows Sent To RDBMS:      1797\n",
      "\n",
      "$LOAD: Total Rows Applied:            1797\n",
      "\n",
      "$LOAD: Total Rows in Error Table 1:   0\n",
      "\n",
      "$LOAD: Total Rows in Error Table 2:   0\n",
      "\n",
      "$LOAD: Total Duplicate Rows:          0\n",
      "\n",
      "$FILE_READER[1]: Total files processed: 1.\n",
      "\n",
      "$LOAD: disconnecting sessions\n",
      "\n",
      "$LOAD: Performance metrics:\n",
      "\n",
      "$LOAD:     MB/sec in Acquisition phase: 0.202\n",
      "\n",
      "$LOAD:     Elapsed time from start to Acquisition phase:   2 second(s)\n",
      "\n",
      "$LOAD:     Elapsed time in Acquisition phase:   3 second(s)\n",
      "\n",
      "$LOAD:     Elapsed time in Application phase: < 1 second\n",
      "\n",
      "$LOAD:     Elapsed time from Application phase to end: < 1 second\n",
      "\n",
      "$LOAD: Total processor time used = '0.064004 Second(s)'\n",
      "\n",
      "$LOAD: Start : Sun Jan 26 22:03:06 2020\n",
      "\n",
      "$LOAD: End   : Sun Jan 26 22:03:11 2020\n",
      "\n",
      "Job step MAIN_STEP completed successfully\n",
      "\n",
      "Job jobtmp completed successfully\n",
      "\n",
      "Job start: Sun Jan 26 22:03:06 2020\n",
      "\n",
      "Job end:   Sun Jan 26 22:03:11 2020\n",
      "\n",
      "Teradata Load Utility Version 16.20.00.09 64-Bit\n",
      "\n",
      "TPT_INFRA: TPT05550: Warning: no Source File Delimiter specified, default \",\" will be used\n",
      "\n",
      "    ...finished. : elapsed time = 7.78.sec\n",
      "start Deleting dumped file /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_tdload_digits_1580542040.csv\n",
      "    ...finished. : elapsed time = 0.00.sec\n",
      "start Deleting /root/tmp_tdwork_tdload_digits_1580542040.csv via SCP\n",
      "    ...finished. : elapsed time = 0.00.sec\n",
      "start Closing SSH\n",
      "    ...finished. : elapsed time = 0.00.sec\n"
     ]
    }
   ],
   "source": [
    "# replace\n",
    "dataloader.tdload_df(df_digits, engine, tablename=\"tdload_digits\", ifExists=\"replace\",\n",
    "                     ssh_ip=\"173.168.56.128\", ssh_username=\"root\", ssh_password=\"root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1797.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Count(*)\n",
       "0    1797.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query(\"select count(*) from tdload_digits\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start dumping DF to /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_tdload_digits_1580542050.csv\n",
      "    ...finished. : elapsed time = 0.15.sec\n",
      "start re-reading /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_tdload_digits_1580542050.csv\n",
      "    ...finished. : elapsed time = 0.02.sec\n",
      "start connecting ssh\n",
      "    ...finished. : elapsed time = 0.21.sec\n",
      "start Uploading File /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_tdload_digits_1580542050.csv to /root/tmp_tdwork_tdload_digits_1580542050.csv\n",
      "Uploading b'tmp_tdwork_tdload_digits_1580542050.csv' progress: 100.00%\n",
      "\n",
      "    ...finished. : elapsed time = 0.12.sec\n",
      "start Loading File /root/tmp_tdwork_tdload_digits_1580542050.csv to DB\n",
      "Teradata Parallel Transporter Version 16.20.00.09 64-Bit\n",
      "\n",
      "The global configuration file '/opt/teradata/client/16.20/tbuild/twbcfg.ini' is used.\n",
      "\n",
      "   Log Directory: /opt/teradata/client/16.20/tbuild/logs\n",
      "\n",
      "   Checkpoint Directory: /opt/teradata/client/16.20/tbuild/checkpoint\n",
      "\n",
      "\n",
      "\n",
      "Job log: /opt/teradata/client/16.20/tbuild/logs/jobtmp-94.out\n",
      "\n",
      "Job id is jobtmp-94, running on linux\n",
      "\n",
      "Teradata Parallel Transporter DataConnector Operator Version 16.20.00.09\n",
      "\n",
      "$FILE_READER[1]: DataConnector Producer operator Instances: 1\n",
      "\n",
      "Teradata Parallel Transporter Stream Operator Version 16.20.00.09\n",
      "\n",
      "$STREAM: private log specified: StreamLog\n",
      "\n",
      "$FILE_READER[1]: ECI operator ID: '$FILE_READER-13834'\n",
      "\n",
      "$FILE_READER[1]: Operator instance 1 processing file '/root/tmp_tdwork_tdload_digits_1580542050.csv'.\n",
      "\n",
      "$STREAM: Start-up Rate: UNLIMITED statements per Minute\n",
      "\n",
      "$STREAM: Operator Command ID for External Command Interface: $STREAM13833\n",
      "\n",
      "$STREAM: connecting sessions\n",
      "\n",
      "$STREAM: entering Load Phase\n",
      "\n",
      "$STREAM: Load Statistics for DML Group 1 :\n",
      "\n",
      "$STREAM: Target Table:  'tdwork.tdload_digits'\n",
      "\n",
      "$STREAM: Rows Inserted: 1797\n",
      "\n",
      "$STREAM: entering Cleanup Phase\n",
      "\n",
      "$STREAM: Total Rows in Error Table :   0\n",
      "\n",
      "$FILE_READER[1]: Total files processed: 1.\n",
      "\n",
      "$STREAM: disconnecting sessions\n",
      "\n",
      "$STREAM: Performance metrics:\n",
      "\n",
      "$STREAM:     MB/sec in Load phase: 0.086\n",
      "\n",
      "$STREAM:     Elapsed time from start to Load phase:   5 second(s)\n",
      "\n",
      "$STREAM:     Elapsed time in Load phase:   7 second(s)\n",
      "\n",
      "$STREAM:     Elapsed time from Load phase to end:   1 second(s)\n",
      "\n",
      "$STREAM: Total processor time used = '0.33602 Second(s)'\n",
      "\n",
      "$STREAM: Start : Sun Jan 26 22:03:14 2020\n",
      "\n",
      "$STREAM: End   : Sun Jan 26 22:03:27 2020\n",
      "\n",
      "Job step MAIN_STEP completed successfully\n",
      "\n",
      "Job jobtmp completed successfully\n",
      "\n",
      "Job start: Sun Jan 26 22:03:14 2020\n",
      "\n",
      "Job end:   Sun Jan 26 22:03:27 2020\n",
      "\n",
      "Teradata Load Utility Version 16.20.00.09 64-Bit\n",
      "\n",
      "TPT_INFRA: TPT05550: Warning: no Source File Delimiter specified, default \",\" will be used\n",
      "\n",
      "    ...finished. : elapsed time = 15.16.sec\n",
      "start Deleting dumped file /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_tdload_digits_1580542050.csv\n",
      "    ...finished. : elapsed time = 0.00.sec\n",
      "start Deleting /root/tmp_tdwork_tdload_digits_1580542050.csv via SCP\n",
      "    ...finished. : elapsed time = 0.00.sec\n",
      "start Closing SSH\n",
      "    ...finished. : elapsed time = 0.00.sec\n"
     ]
    }
   ],
   "source": [
    "# insert\n",
    "dataloader.tdload_df(df_digits, engine, tablename=\"tdload_digits\", ifExists=\"insert\",\n",
    "                     ssh_ip=\"173.168.56.128\", ssh_username=\"root\", ssh_password=\"root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3594.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Count(*)\n",
       "0    3594.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query(\"select count(*) from tdload_digits\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start dumping DF to /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_tdload_digits_1580542066.csv\n",
      "    ...finished. : elapsed time = 0.15.sec\n",
      "start re-reading /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_tdload_digits_1580542066.csv\n",
      "    ...finished. : elapsed time = 0.02.sec\n",
      "start Deleting dumped file /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_tdload_digits_1580542066.csv\n",
      "    ...finished. : elapsed time = 0.00.sec\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "tdload_digits.tdwork is already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-511f160119df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# errror if table already exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m dataloader.tdload_df(df_digits, engine, tablename=\"tdload_digits\", ifExists=\"error\",\n\u001b[0m\u001b[1;32m      3\u001b[0m                      ssh_ip=\"173.168.56.128\", ssh_username=\"root\", ssh_password=\"root\")\n",
      "\u001b[0;32m~/Documents/Github/sklearn2vantage/dataloader.py\u001b[0m in \u001b[0;36mtdload_df\u001b[0;34m(df, engine, tablename, ssh_ip, ssh_username, dbname, ifExists, compress, dtype, ssh_password, ssh_keypath, ssh_folder, dump_folder, saveIndex, indexList, isIndexUnique, verbose)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# 2. create table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         createTable(df, engine, tablename, dbname,\n\u001b[0m\u001b[1;32m    323\u001b[0m                     ifExists, indexList, isIndexUnique, dtype)\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/sklearn2vantage/dataloader.py\u001b[0m in \u001b[0;36mcreateTable\u001b[0;34m(df, engine, tablename, dbname, ifExists, indexList, isIndexUnique, dtype)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mifExists\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"error\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtableIsExist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtablename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdbname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{tablename}.{dbname} is already exists.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mifExists\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"insert\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtableIsExist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtablename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdbname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: tdload_digits.tdwork is already exists."
     ]
    }
   ],
   "source": [
    "# errror if table already exists\n",
    "dataloader.tdload_df(df_digits, engine, tablename=\"tdload_digits\", ifExists=\"error\",\n",
    "                     ssh_ip=\"173.168.56.128\", ssh_username=\"root\", ssh_password=\"root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start dumping DF to /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_tdload_digits_1580542085.csv\n",
      "    ...finished. : elapsed time = 0.62.sec\n",
      "start re-reading /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_tdload_digits_1580542085.csv\n",
      "    ...finished. : elapsed time = 0.26.sec\n",
      "droped table tdwork.tdload_digits\n",
      "created table \n",
      "\n",
      "    create table tdwork.tdload_digits (\n",
      "        idx integer\n",
      "    ,col_0 float\n",
      "    ,col_1 float\n",
      "    ,col_2 float\n",
      "    ,col_3 float\n",
      "    ,col_4 float\n",
      "    ,col_5 float\n",
      "    ,col_6 float\n",
      "    ,col_7 float\n",
      "    ,col_8 float\n",
      "    ,col_9 float\n",
      "    ,col_10 float\n",
      "    ,col_11 float\n",
      "    ,col_12 float\n",
      "    ,col_13 float\n",
      "    ,col_14 float\n",
      "    ,col_15 float\n",
      "    ,col_16 float\n",
      "    ,col_17 float\n",
      "    ,col_18 float\n",
      "    ,col_19 float\n",
      "    ,col_20 float\n",
      "    ,col_21 float\n",
      "    ,col_22 float\n",
      "    ,col_23 float\n",
      "    ,col_24 float\n",
      "    ,col_25 float\n",
      "    ,col_26 float\n",
      "    ,col_27 float\n",
      "    ,col_28 float\n",
      "    ,col_29 float\n",
      "    ,col_30 float\n",
      "    ,col_31 float\n",
      "    ,col_32 float\n",
      "    ,col_33 float\n",
      "    ,col_34 float\n",
      "    ,col_35 float\n",
      "    ,col_36 float\n",
      "    ,col_37 float\n",
      "    ,col_38 float\n",
      "    ,col_39 float\n",
      "    ,col_40 float\n",
      "    ,col_41 float\n",
      "    ,col_42 float\n",
      "    ,col_43 float\n",
      "    ,col_44 float\n",
      "    ,col_45 float\n",
      "    ,col_46 float\n",
      "    ,col_47 float\n",
      "    ,col_48 float\n",
      "    ,col_49 float\n",
      "    ,col_50 float\n",
      "    ,col_51 float\n",
      "    ,col_52 float\n",
      "    ,col_53 float\n",
      "    ,col_54 float\n",
      "    ,col_55 float\n",
      "    ,col_56 float\n",
      "    ,col_57 float\n",
      "    ,col_58 float\n",
      "    ,col_59 float\n",
      "    ,col_60 float\n",
      "    ,col_61 float\n",
      "    ,col_62 float\n",
      "    ,col_63 float\n",
      "    ,target integer\n",
      "    ) unique primary index (idx)\n",
      "    \n",
      "start connecting ssh\n",
      "    ...finished. : elapsed time = 0.49.sec\n",
      "start Uploading File /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_tdload_digits_1580542085.csv to /root/tmp_tdwork_tdload_digits_1580542085.csv\n",
      "start Archiving /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_tdload_digits_1580542085.csv to /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_tdload_digits_1580542085.csv.xz\n",
      "\n",
      "    ...finished. : elapsed time = 1.30.sec\n",
      "Uploading b'tmp_tdwork_tdload_digits_1580542085.csv.xz' progress: 100.00%\n",
      "\n",
      "start Unarchiving /root/tmp_tdwork_tdload_digits_1580542085.csv.xz\n",
      "tmp_tdwork_tdload_digits_1580542085.csv\n",
      "\n",
      "    ...finished. : elapsed time = 0.27.sec\n",
      "start Deleting archive /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_tdload_digits_1580542085.csv.xz\n",
      "    ...finished. : elapsed time = 0.00.sec\n",
      "start Deleting archive /root/tmp_tdwork_tdload_digits_1580542085.csv.xz via SCP\n",
      "    ...finished. : elapsed time = 0.01.sec\n",
      "    ...finished. : elapsed time = 2.34.sec\n",
      "start Loading File /root/tmp_tdwork_tdload_digits_1580542085.csv to DB\n",
      "Teradata Parallel Transporter Version 16.20.00.09 64-Bit\n",
      "\n",
      "The global configuration file '/opt/teradata/client/16.20/tbuild/twbcfg.ini' is used.\n",
      "\n",
      "   Log Directory: /opt/teradata/client/16.20/tbuild/logs\n",
      "\n",
      "   Checkpoint Directory: /opt/teradata/client/16.20/tbuild/checkpoint\n",
      "\n",
      "\n",
      "\n",
      "Job log: /opt/teradata/client/16.20/tbuild/logs/jobtmp-95.out\n",
      "\n",
      "Job id is jobtmp-95, running on linux\n",
      "\n",
      "Teradata Parallel Transporter DataConnector Operator Version 16.20.00.09\n",
      "\n",
      "$FILE_READER[1]: DataConnector Producer operator Instances: 1\n",
      "\n",
      "Teradata Parallel Transporter Load Operator Version 16.20.00.09\n",
      "\n",
      "$LOAD: private log specified: LoadLog\n",
      "\n",
      "$FILE_READER[1]: ECI operator ID: '$FILE_READER-14041'\n",
      "\n",
      "$FILE_READER[1]: Operator instance 1 processing file '/root/tmp_tdwork_tdload_digits_1580542085.csv'.\n",
      "\n",
      "$LOAD: connecting sessions\n",
      "\n",
      "$LOAD: preparing target table\n",
      "\n",
      "$LOAD: entering Acquisition Phase\n",
      "\n",
      "$LOAD: entering Application Phase\n",
      "\n",
      "$LOAD: Statistics for Target Table:  'tdwork.tdload_digits'\n",
      "\n",
      "$LOAD: Total Rows Sent To RDBMS:      1797\n",
      "\n",
      "$LOAD: Total Rows Applied:            1797\n",
      "\n",
      "$LOAD: Total Rows in Error Table 1:   0\n",
      "\n",
      "$LOAD: Total Rows in Error Table 2:   0\n",
      "\n",
      "$LOAD: Total Duplicate Rows:          0\n",
      "\n",
      "$FILE_READER[1]: Total files processed: 1.\n",
      "\n",
      "$LOAD: disconnecting sessions\n",
      "\n",
      "$LOAD: Performance metrics:\n",
      "\n",
      "$LOAD:     MB/sec in Acquisition phase: 0.205\n",
      "\n",
      "$LOAD:     Elapsed time from start to Acquisition phase:   4 second(s)\n",
      "\n",
      "$LOAD:     Elapsed time in Acquisition phase:   3 second(s)\n",
      "\n",
      "$LOAD:     Elapsed time in Application phase: < 1 second\n",
      "\n",
      "$LOAD:     Elapsed time from Application phase to end:   2 second(s)\n",
      "\n",
      "$LOAD: Total processor time used = '0.192012 Second(s)'\n",
      "\n",
      "$LOAD: Start : Sun Jan 26 22:03:56 2020\n",
      "\n",
      "$LOAD: End   : Sun Jan 26 22:04:05 2020\n",
      "\n",
      "Job step MAIN_STEP completed successfully\n",
      "\n",
      "Job jobtmp completed successfully\n",
      "\n",
      "Job start: Sun Jan 26 22:03:56 2020\n",
      "\n",
      "Job end:   Sun Jan 26 22:04:05 2020\n",
      "\n",
      "Teradata Load Utility Version 16.20.00.09 64-Bit\n",
      "\n",
      "TPT_INFRA: TPT05550: Warning: no Source File Delimiter specified, default \",\" will be used\n",
      "\n",
      "    ...finished. : elapsed time = 11.93.sec\n",
      "start Deleting dumped file /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_tdload_digits_1580542085.csv\n",
      "    ...finished. : elapsed time = 0.00.sec\n",
      "start Deleting /root/tmp_tdwork_tdload_digits_1580542085.csv via SCP\n",
      "    ...finished. : elapsed time = 0.00.sec\n",
      "start Closing SSH\n",
      "    ...finished. : elapsed time = 0.00.sec\n"
     ]
    }
   ],
   "source": [
    "# saveIndex, make index (\"index\"), which is unique, and use xz compressing for scp\n",
    "dataloader.tdload_df(df_digits, engine, tablename=\"tdload_digits\", ifExists=\"replace\",\n",
    "                     ssh_ip=\"173.168.56.128\", ssh_username=\"root\", ssh_password=\"root\",\n",
    "                     saveIndex=True, indexList=[\"index\"], isIndexUnique=True, compress=\"xz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic = pd.read_csv(\"titanic/train.csv\").set_index(\"PassengerId\")\n",
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "droped table tdwork.titanic_train\n",
      "created table \n",
      "\n",
      "    create table tdwork.titanic_train (\n",
      "        PassengerId integer\n",
      "    ,Survived integer\n",
      "    ,Pclass integer\n",
      "    ,Name varchar(82)\n",
      "    ,Sex varchar(6)\n",
      "    ,Age float\n",
      "    ,SibSp integer\n",
      "    ,Parch integer\n",
      "    ,Ticket varchar(18)\n",
      "    ,Fare float\n",
      "    ,Cabin varchar(15)\n",
      "    ,Embarked varchar(3)\n",
      "    ) unique primary index (PassengerId)\n",
      "    \n",
      "\n",
      "\n",
      "$LOAD: Total Rows Sent To RDBMS:      891\n",
      "\n",
      "$LOAD: Total Rows Applied:            891\n",
      "\n",
      "$LOAD: Total Rows in Error Table 1:   0\n",
      "\n",
      "$LOAD: Total Rows in Error Table 2:   0\n",
      "\n",
      "Job step MAIN_STEP completed successfully\n",
      "\n",
      "Job jobtmp completed successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test with titanic data, with less verbosity\n",
    "dataloader.tdload_df(df_titanic, engine, tablename=\"titanic_train\", ifExists=\"replace\",\n",
    "                     ssh_ip=\"173.168.56.128\", ssh_username=\"root\", ssh_password=\"root\",\n",
    "                     saveIndex=True, indexList=[\"PassengerId\"], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_house = pd.read_csv(\"house-prices-advanced-regression-techniques/train.csv\")\n",
    "df_house.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start dumping DF to /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_house_train_1580542120.csv\n",
      "    ...finished. : elapsed time = 0.36.sec\n",
      "start re-reading /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_house_train_1580542120.csv\n",
      "    ...finished. : elapsed time = 0.08.sec\n",
      "droped table tdwork.house_train\n",
      "created table \n",
      "\n",
      "    create table tdwork.house_train (\n",
      "        Id integer\n",
      "    ,MSSubClass integer\n",
      "    ,MSZoning varchar(7)\n",
      "    ,LotFrontage float\n",
      "    ,LotArea integer\n",
      "    ,Street varchar(4)\n",
      "    ,Alley varchar(4)\n",
      "    ,LotShape varchar(3)\n",
      "    ,LandContour varchar(3)\n",
      "    ,Utilities varchar(6)\n",
      "    ,LotConfig varchar(7)\n",
      "    ,LandSlope varchar(3)\n",
      "    ,Neighborhood varchar(7)\n",
      "    ,Condition1 varchar(6)\n",
      "    ,Condition2 varchar(6)\n",
      "    ,BldgType varchar(6)\n",
      "    ,HouseStyle varchar(6)\n",
      "    ,OverallQual integer\n",
      "    ,OverallCond integer\n",
      "    ,YearBuilt integer\n",
      "    ,YearRemodAdd integer\n",
      "    ,RoofStyle varchar(7)\n",
      "    ,RoofMatl varchar(7)\n",
      "    ,Exterior1st varchar(7)\n",
      "    ,Exterior2nd varchar(7)\n",
      "    ,MasVnrType varchar(7)\n",
      "    ,MasVnrArea float\n",
      "    ,ExterQual varchar(2)\n",
      "    ,ExterCond varchar(2)\n",
      "    ,Foundation varchar(6)\n",
      "    ,BsmtQual varchar(3)\n",
      "    ,BsmtCond varchar(3)\n",
      "    ,BsmtExposure varchar(3)\n",
      "    ,BsmtFinType1 varchar(3)\n",
      "    ,BsmtFinSF1 integer\n",
      "    ,BsmtFinType2 varchar(3)\n",
      "    ,BsmtFinSF2 integer\n",
      "    ,BsmtUnfSF integer\n",
      "    ,TotalBsmtSF integer\n",
      "    ,Heating varchar(5)\n",
      "    ,HeatingQC varchar(2)\n",
      "    ,CentralAir varchar(1)\n",
      "    ,Electrical varchar(5)\n",
      "    ,col_1stFlrSF integer\n",
      "    ,col_2ndFlrSF integer\n",
      "    ,LowQualFinSF integer\n",
      "    ,GrLivArea integer\n",
      "    ,BsmtFullBath integer\n",
      "    ,BsmtHalfBath integer\n",
      "    ,FullBath integer\n",
      "    ,HalfBath integer\n",
      "    ,BedroomAbvGr integer\n",
      "    ,KitchenAbvGr integer\n",
      "    ,KitchenQual varchar(2)\n",
      "    ,TotRmsAbvGrd integer\n",
      "    ,Functional varchar(4)\n",
      "    ,Fireplaces integer\n",
      "    ,FireplaceQu varchar(3)\n",
      "    ,GarageType varchar(7)\n",
      "    ,GarageYrBlt float\n",
      "    ,GarageFinish varchar(3)\n",
      "    ,GarageCars integer\n",
      "    ,GarageArea integer\n",
      "    ,GarageQual varchar(3)\n",
      "    ,GarageCond varchar(3)\n",
      "    ,PavedDrive varchar(1)\n",
      "    ,WoodDeckSF integer\n",
      "    ,OpenPorchSF integer\n",
      "    ,EnclosedPorch integer\n",
      "    ,col_3SsnPorch integer\n",
      "    ,ScreenPorch integer\n",
      "    ,PoolArea integer\n",
      "    ,PoolQC varchar(3)\n",
      "    ,Fence varchar(5)\n",
      "    ,MiscFeature varchar(4)\n",
      "    ,MiscVal integer\n",
      "    ,MoSold integer\n",
      "    ,YrSold integer\n",
      "    ,SaleType varchar(5)\n",
      "    ,SaleCondition varchar(7)\n",
      "    ,SalePrice integer\n",
      "    ) no primary index\n",
      "    \n",
      "start connecting ssh\n",
      "    ...finished. : elapsed time = 0.34.sec\n",
      "start Uploading File /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_house_train_1580542120.csv to /root/tmp_tdwork_house_train_1580542120.csv\n",
      "start Archiving /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_house_train_1580542120.csv to /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_house_train_1580542120.csv.gz\n",
      "\n",
      "    ...finished. : elapsed time = 0.07.sec\n",
      "Uploading b'tmp_tdwork_house_train_1580542120.csv.gz' progress: 100.00%\n",
      "\n",
      "start Unarchiving /root/tmp_tdwork_house_train_1580542120.csv.gz\n",
      "tmp_tdwork_house_train_1580542120.csv\n",
      "\n",
      "    ...finished. : elapsed time = 0.14.sec\n",
      "start Deleting archive /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_house_train_1580542120.csv.gz\n",
      "    ...finished. : elapsed time = 0.00.sec\n",
      "start Deleting archive /root/tmp_tdwork_house_train_1580542120.csv.gz via SCP\n",
      "    ...finished. : elapsed time = 0.00.sec\n",
      "    ...finished. : elapsed time = 0.54.sec\n",
      "start Loading File /root/tmp_tdwork_house_train_1580542120.csv to DB\n",
      "Teradata Parallel Transporter Version 16.20.00.09 64-Bit\n",
      "\n",
      "The global configuration file '/opt/teradata/client/16.20/tbuild/twbcfg.ini' is used.\n",
      "\n",
      "   Log Directory: /opt/teradata/client/16.20/tbuild/logs\n",
      "\n",
      "   Checkpoint Directory: /opt/teradata/client/16.20/tbuild/checkpoint\n",
      "\n",
      "\n",
      "\n",
      "Job log: /opt/teradata/client/16.20/tbuild/logs/jobtmp-97.out\n",
      "\n",
      "Job id is jobtmp-97, running on linux\n",
      "\n",
      "Teradata Parallel Transporter DataConnector Operator Version 16.20.00.09\n",
      "\n",
      "Teradata Parallel Transporter Load Operator Version 16.20.00.09\n",
      "\n",
      "$LOAD: private log specified: LoadLog\n",
      "\n",
      "$FILE_READER[1]: DataConnector Producer operator Instances: 1\n",
      "\n",
      "$FILE_READER[1]: ECI operator ID: '$FILE_READER-14406'\n",
      "\n",
      "$FILE_READER[1]: Operator instance 1 processing file '/root/tmp_tdwork_house_train_1580542120.csv'.\n",
      "\n",
      "$LOAD: connecting sessions\n",
      "\n",
      "$LOAD: preparing target table\n",
      "\n",
      "$LOAD: entering Acquisition Phase\n",
      "\n",
      "$LOAD: entering Application Phase\n",
      "\n",
      "$LOAD: Statistics for Target Table:  'tdwork.house_train'\n",
      "\n",
      "$LOAD: Total Rows Sent To RDBMS:      1460\n",
      "\n",
      "$LOAD: Total Rows Applied:            1460\n",
      "\n",
      "$LOAD: Total Rows in Error Table 1:   0\n",
      "\n",
      "$LOAD: Total Rows in Error Table 2:   0\n",
      "\n",
      "$LOAD: Total Duplicate Rows:          0\n",
      "\n",
      "$FILE_READER[1]: Total files processed: 1.\n",
      "\n",
      "$LOAD: disconnecting sessions\n",
      "\n",
      "$LOAD: Performance metrics:\n",
      "\n",
      "$LOAD:     MB/sec in Acquisition phase: 0.142\n",
      "\n",
      "$LOAD:     Elapsed time from start to Acquisition phase:   2 second(s)\n",
      "\n",
      "$LOAD:     Elapsed time in Acquisition phase:   4 second(s)\n",
      "\n",
      "$LOAD:     Elapsed time in Application phase: < 1 second\n",
      "\n",
      "$LOAD:     Elapsed time from Application phase to end:   1 second(s)\n",
      "\n",
      "$LOAD: Total processor time used = '0.132008 Second(s)'\n",
      "\n",
      "$LOAD: Start : Sun Jan 26 22:04:28 2020\n",
      "\n",
      "$LOAD: End   : Sun Jan 26 22:04:35 2020\n",
      "\n",
      "Job step MAIN_STEP completed successfully\n",
      "\n",
      "Job jobtmp completed successfully\n",
      "\n",
      "Job start: Sun Jan 26 22:04:28 2020\n",
      "\n",
      "Job end:   Sun Jan 26 22:04:35 2020\n",
      "\n",
      "Teradata Load Utility Version 16.20.00.09 64-Bit\n",
      "\n",
      "TPT_INFRA: TPT05550: Warning: no Source File Delimiter specified, default \",\" will be used\n",
      "\n",
      "    ...finished. : elapsed time = 9.66.sec\n",
      "start Deleting dumped file /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_house_train_1580542120.csv\n",
      "    ...finished. : elapsed time = 0.00.sec\n",
      "start Deleting /root/tmp_tdwork_house_train_1580542120.csv via SCP\n",
      "    ...finished. : elapsed time = 0.00.sec\n",
      "start Closing SSH\n",
      "    ...finished. : elapsed time = 0.00.sec\n"
     ]
    }
   ],
   "source": [
    "# test with house data, with gz compressing\n",
    "dataloader.tdload_df(df_house, engine, tablename=\"house_train\", ifExists=\"replace\",\n",
    "          ssh_ip=\"173.168.56.128\", ssh_username=\"root\", ssh_password=\"root\", compress=\"gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_int</th>\n",
       "      <th>c_float</th>\n",
       "      <th>c_bigint</th>\n",
       "      <th>c_bool</th>\n",
       "      <th>c_string</th>\n",
       "      <th>c_list</th>\n",
       "      <th>c_timedelta</th>\n",
       "      <th>c_date</th>\n",
       "      <th>c_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1000000000000</td>\n",
       "      <td>True</td>\n",
       "      <td>a</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>00:01:02</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2020-01-01 10:10:10.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>2000000000000</td>\n",
       "      <td>False</td>\n",
       "      <td>b</td>\n",
       "      <td>[4, 5, 6]</td>\n",
       "      <td>00:03:01</td>\n",
       "      <td>1998-12-02</td>\n",
       "      <td>2020-01-01 10:10:10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3000000000000</td>\n",
       "      <td>True</td>\n",
       "      <td>c</td>\n",
       "      <td>[7, 8, 9]</td>\n",
       "      <td>05:02:01</td>\n",
       "      <td>1980-04-01</td>\n",
       "      <td>2020-01-01 10:10:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4000000000000</td>\n",
       "      <td>False</td>\n",
       "      <td>d</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>01:01:08</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>2020-01-01 10:10:05.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c_int  c_float       c_bigint  c_bool c_string     c_list c_timedelta  \\\n",
       "0      1      1.2  1000000000000    True        a  [1, 2, 3]    00:01:02   \n",
       "1      2     -0.3  2000000000000   False        b  [4, 5, 6]    00:03:01   \n",
       "2      3      0.9  3000000000000    True        c  [7, 8, 9]    05:02:01   \n",
       "3      4      1.5  4000000000000   False        d  [1, 2, 3]    01:01:08   \n",
       "\n",
       "      c_date             c_timestamp  \n",
       "0 2020-01-01 2020-01-01 10:10:10.090  \n",
       "1 1998-12-02 2020-01-01 10:10:10.000  \n",
       "2 1980-04-01 2020-01-01 10:10:00.000  \n",
       "3 2008-01-01 2020-01-01 10:10:05.000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create sample data\n",
    "df_sample = pd.DataFrame({\"c_int\":[1,2,3,4], \"c_float\":[1.2, -0.3, 0.9, 1.5],\n",
    "                          \"c_bigint\":[int(1e12), int(2e12), int(3e12), int(4e12)],\n",
    "                         \"c_bool\":[True,False,True,False], \n",
    "                          \"c_string\":[\"a\", \"b\", \"c\", \"d\"],\n",
    "                         \"c_list\":[[1,2,3], [4,5,6], [7,8,9], [1,2,3]],\n",
    "                         \"c_timedelta\":pd.to_timedelta([\"00:01:02\", \"00:03:01\",\n",
    "                                                     \"05:02:01\", \"1:01:08\"]),\n",
    "                         \"c_date\":pd.to_datetime([\"2020/1/1\",\"1998/12/2\",\n",
    "                                                   \"1980/4/1\",\"2008/1/1\"]),\n",
    "                         \"c_timestamp\":pd.to_datetime([\"2020/1/1 10:10:10.09\",\n",
    "                                                   \"2020/1/1 10:10:10\",\n",
    "                                                   \"2020/1/1 10:10\",\n",
    "                                                   \"2020/1/1 10:10:05\"])})\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start dumping DF to /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_t_sample_1580542134.csv\n",
      "    ...finished. : elapsed time = 0.01.sec\n",
      "start re-reading /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_t_sample_1580542134.csv\n",
      "    ...finished. : elapsed time = 0.01.sec\n",
      "droped table tdwork.t_sample\n",
      "created table \n",
      "\n",
      "    create table tdwork.t_sample (\n",
      "        c_int integer\n",
      "    ,c_float float\n",
      "    ,c_bigint bigint\n",
      "    ,c_bool varchar(5)\n",
      "    ,c_string varchar(1)\n",
      "    ,c_list varchar(9)\n",
      "    ,c_timedelta varchar(25)\n",
      "    ,c_date varchar(23)\n",
      "    ,c_timestamp varchar(23)\n",
      "    ) no primary index\n",
      "    \n",
      "start connecting ssh\n",
      "    ...finished. : elapsed time = 0.51.sec\n",
      "start Uploading File /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_t_sample_1580542134.csv to /root/tmp_tdwork_t_sample_1580542134.csv\n",
      "start Archiving /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_t_sample_1580542134.csv to /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_t_sample_1580542134.csv.bz2\n",
      "\n",
      "    ...finished. : elapsed time = 0.03.sec\n",
      "Uploading b'tmp_tdwork_t_sample_1580542134.csv.bz2' progress: 100.00%\n",
      "\n",
      "start Unarchiving /root/tmp_tdwork_t_sample_1580542134.csv.bz2\n",
      "tmp_tdwork_t_sample_1580542134.csv\n",
      "\n",
      "    ...finished. : elapsed time = 0.31.sec\n",
      "start Deleting archive /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_t_sample_1580542134.csv.bz2\n",
      "    ...finished. : elapsed time = 0.00.sec\n",
      "start Deleting archive /root/tmp_tdwork_t_sample_1580542134.csv.bz2 via SCP\n",
      "    ...finished. : elapsed time = 0.00.sec\n",
      "    ...finished. : elapsed time = 0.90.sec\n",
      "start Loading File /root/tmp_tdwork_t_sample_1580542134.csv to DB\n",
      "Teradata Parallel Transporter Version 16.20.00.09 64-Bit\n",
      "\n",
      "The global configuration file '/opt/teradata/client/16.20/tbuild/twbcfg.ini' is used.\n",
      "\n",
      "   Log Directory: /opt/teradata/client/16.20/tbuild/logs\n",
      "\n",
      "   Checkpoint Directory: /opt/teradata/client/16.20/tbuild/checkpoint\n",
      "\n",
      "\n",
      "\n",
      "Job log: /opt/teradata/client/16.20/tbuild/logs/jobtmp-98.out\n",
      "\n",
      "Job id is jobtmp-98, running on linux\n",
      "\n",
      "Teradata Parallel Transporter DataConnector Operator Version 16.20.00.09\n",
      "\n",
      "Teradata Parallel Transporter Load Operator Version 16.20.00.09\n",
      "\n",
      "$LOAD: private log specified: LoadLog\n",
      "\n",
      "$FILE_READER[1]: DataConnector Producer operator Instances: 1\n",
      "\n",
      "$FILE_READER[1]: ECI operator ID: '$FILE_READER-14608'\n",
      "\n",
      "$FILE_READER[1]: Operator instance 1 processing file '/root/tmp_tdwork_t_sample_1580542134.csv'.\n",
      "\n",
      "$LOAD: connecting sessions\n",
      "\n",
      "$LOAD: preparing target table\n",
      "\n",
      "$LOAD: entering Acquisition Phase\n",
      "\n",
      "$LOAD: entering Application Phase\n",
      "\n",
      "$LOAD: Statistics for Target Table:  'tdwork.t_sample'\n",
      "\n",
      "$LOAD: Total Rows Sent To RDBMS:      4\n",
      "\n",
      "$LOAD: Total Rows Applied:            4\n",
      "\n",
      "$LOAD: Total Rows in Error Table 1:   0\n",
      "\n",
      "$LOAD: Total Rows in Error Table 2:   0\n",
      "\n",
      "$LOAD: Total Duplicate Rows:          0\n",
      "\n",
      "$FILE_READER[1]: Total files processed: 1.\n",
      "\n",
      "$LOAD: disconnecting sessions\n",
      "\n",
      "$LOAD: Performance metrics:\n",
      "\n",
      "$LOAD:     MB/sec in Acquisition phase: 0.000\n",
      "\n",
      "$LOAD:     Elapsed time from start to Acquisition phase:   4 second(s)\n",
      "\n",
      "$LOAD:     Elapsed time in Acquisition phase:   3 second(s)\n",
      "\n",
      "$LOAD:     Elapsed time in Application phase: < 1 second\n",
      "\n",
      "$LOAD:     Elapsed time from Application phase to end:   1 second(s)\n",
      "\n",
      "$LOAD: Total processor time used = '0.184011 Second(s)'\n",
      "\n",
      "$LOAD: Start : Sun Jan 26 22:04:40 2020\n",
      "\n",
      "$LOAD: End   : Sun Jan 26 22:04:48 2020\n",
      "\n",
      "Job step MAIN_STEP completed successfully\n",
      "\n",
      "Job jobtmp completed successfully\n",
      "\n",
      "Job start: Sun Jan 26 22:04:40 2020\n",
      "\n",
      "Job end:   Sun Jan 26 22:04:48 2020\n",
      "\n",
      "Teradata Load Utility Version 16.20.00.09 64-Bit\n",
      "\n",
      "TPT_INFRA: TPT05550: Warning: no Source File Delimiter specified, default \",\" will be used\n",
      "\n",
      "    ...finished. : elapsed time = 11.17.sec\n",
      "start Deleting dumped file /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_t_sample_1580542134.csv\n",
      "    ...finished. : elapsed time = 0.00.sec\n",
      "start Deleting /root/tmp_tdwork_t_sample_1580542134.csv via SCP\n",
      "    ...finished. : elapsed time = 0.00.sec\n",
      "start Closing SSH\n",
      "    ...finished. : elapsed time = 0.00.sec\n"
     ]
    }
   ],
   "source": [
    "# test with sample data\n",
    "dataloader.tdload_df(df_sample, engine, tablename=\"t_sample\", ifExists=\"replace\",\n",
    "                     ssh_ip=\"173.168.56.128\", ssh_username=\"root\", ssh_password=\"root\",\n",
    "                     compress=\"bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start dumping DF to /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_t_sample_1580542147.csv\n",
      "    ...finished. : elapsed time = 0.01.sec\n",
      "start re-reading /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_t_sample_1580542147.csv\n",
      "    ...finished. : elapsed time = 0.01.sec\n",
      "droped table tdwork.t_sample\n",
      "created table \n",
      "\n",
      "    create table tdwork.t_sample (\n",
      "        c_int varchar(5)\n",
      "    ,c_float float\n",
      "    ,c_bigint float\n",
      "    ,c_bool varchar(5)\n",
      "    ,c_string varchar(1)\n",
      "    ,c_list varchar(9)\n",
      "    ,c_timedelta varchar(25)\n",
      "    ,c_date varchar(23)\n",
      "    ,c_timestamp varchar(23)\n",
      "    ) no primary index\n",
      "    \n",
      "start connecting ssh\n",
      "    ...finished. : elapsed time = 1.42.sec\n",
      "start Uploading File /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_t_sample_1580542147.csv to /root/tmp_tdwork_t_sample_1580542147.csv\n",
      "start Archiving /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_t_sample_1580542147.csv to /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_t_sample_1580542147.csv.bz2\n",
      "\n",
      "    ...finished. : elapsed time = 0.04.sec\n",
      "Uploading b'tmp_tdwork_t_sample_1580542147.csv.bz2' progress: 100.00%\n",
      "\n",
      "start Unarchiving /root/tmp_tdwork_t_sample_1580542147.csv.bz2\n",
      "tmp_tdwork_t_sample_1580542147.csv\n",
      "\n",
      "    ...finished. : elapsed time = 1.04.sec\n",
      "start Deleting archive /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_t_sample_1580542147.csv.bz2\n",
      "    ...finished. : elapsed time = 0.00.sec\n",
      "start Deleting archive /root/tmp_tdwork_t_sample_1580542147.csv.bz2 via SCP\n",
      "    ...finished. : elapsed time = 0.00.sec\n",
      "    ...finished. : elapsed time = 4.44.sec\n",
      "start Loading File /root/tmp_tdwork_t_sample_1580542147.csv to DB\n",
      "Teradata Parallel Transporter Version 16.20.00.09 64-Bit\n",
      "\n",
      "The global configuration file '/opt/teradata/client/16.20/tbuild/twbcfg.ini' is used.\n",
      "\n",
      "   Log Directory: /opt/teradata/client/16.20/tbuild/logs\n",
      "\n",
      "   Checkpoint Directory: /opt/teradata/client/16.20/tbuild/checkpoint\n",
      "\n",
      "\n",
      "\n",
      "Job log: /opt/teradata/client/16.20/tbuild/logs/jobtmp-99.out\n",
      "\n",
      "Job id is jobtmp-99, running on linux\n",
      "\n",
      "Teradata Parallel Transporter Load Operator Version 16.20.00.09\n",
      "\n",
      "$LOAD: private log specified: LoadLog\n",
      "\n",
      "Teradata Parallel Transporter DataConnector Operator Version 16.20.00.09\n",
      "\n",
      "$FILE_READER[1]: DataConnector Producer operator Instances: 1\n",
      "\n",
      "$FILE_READER[1]: ECI operator ID: '$FILE_READER-15032'\n",
      "\n",
      "$FILE_READER[1]: Operator instance 1 processing file '/root/tmp_tdwork_t_sample_1580542147.csv'.\n",
      "\n",
      "$LOAD: connecting sessions\n",
      "\n",
      "$LOAD: preparing target table\n",
      "\n",
      "$LOAD: entering Acquisition Phase\n",
      "\n",
      "$LOAD: entering Application Phase\n",
      "\n",
      "$LOAD: Statistics for Target Table:  'tdwork.t_sample'\n",
      "\n",
      "$LOAD: Total Rows Sent To RDBMS:      4\n",
      "\n",
      "$LOAD: Total Rows Applied:            4\n",
      "\n",
      "$LOAD: Total Rows in Error Table 1:   0\n",
      "\n",
      "$LOAD: Total Rows in Error Table 2:   0\n",
      "\n",
      "$LOAD: Total Duplicate Rows:          0\n",
      "\n",
      "$FILE_READER[1]: Total files processed: 1.\n",
      "\n",
      "$LOAD: disconnecting sessions\n",
      "\n",
      "$LOAD: Performance metrics:\n",
      "\n",
      "$LOAD:     MB/sec in Acquisition phase: 0.000\n",
      "\n",
      "$LOAD:     Elapsed time from start to Acquisition phase:   8 second(s)\n",
      "\n",
      "$LOAD:     Elapsed time in Acquisition phase:   3 second(s)\n",
      "\n",
      "$LOAD:     Elapsed time in Application phase:   1 second(s)\n",
      "\n",
      "$LOAD:     Elapsed time from Application phase to end:   1 second(s)\n",
      "\n",
      "$LOAD: Total processor time used = '0.144008 Second(s)'\n",
      "\n",
      "$LOAD: Start : Sun Jan 26 22:05:04 2020\n",
      "\n",
      "$LOAD: End   : Sun Jan 26 22:05:17 2020\n",
      "\n",
      "Job step MAIN_STEP completed successfully\n",
      "\n",
      "Job jobtmp completed successfully\n",
      "\n",
      "Job start: Sun Jan 26 22:05:04 2020\n",
      "\n",
      "Job end:   Sun Jan 26 22:05:18 2020\n",
      "\n",
      "Teradata Load Utility Version 16.20.00.09 64-Bit\n",
      "\n",
      "TPT_INFRA: TPT05550: Warning: no Source File Delimiter specified, default \",\" will be used\n",
      "\n",
      "    ...finished. : elapsed time = 20.99.sec\n",
      "start Deleting dumped file /Users/akihirosanada/Documents/Github/sklearn2vantage/tmp_tdwork_t_sample_1580542147.csv\n",
      "    ...finished. : elapsed time = 0.00.sec\n",
      "start Deleting /root/tmp_tdwork_t_sample_1580542147.csv via SCP\n",
      "    ...finished. : elapsed time = 0.00.sec\n",
      "start Closing SSH\n",
      "    ...finished. : elapsed time = 0.00.sec\n"
     ]
    }
   ],
   "source": [
    "# test with sample data and data type overwriting\n",
    "dataloader.tdload_df(df_sample, engine, tablename=\"t_sample\", ifExists=\"replace\",\n",
    "                     ssh_ip=\"173.168.56.128\", ssh_username=\"root\", ssh_password=\"root\",\n",
    "                     compress=\"bz2\", dtype={\"c_int\": \"varchar(5)\", \"c_bigint\":\"float\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sklearn2vantage] *",
   "language": "python",
   "name": "conda-env-sklearn2vantage-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
